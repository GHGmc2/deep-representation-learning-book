\providecommand{\toplevelprefix}{../..}  %
\documentclass[../../book-main_ro.tex]{subfiles}

\begin{document}

\chapter*{Prefață}

\begin{center}
``{\em Toate drumurile duc la Roma}.''

\end{center}
\vspace{5mm}

Această carte dezvăluie și studiază o problemă comună și fundamentală din spatele aproape tuturor practicilor moderne de inteligență (artificială). Aceasta este: {\em cum să învățăm eficient și eficace o distribuție de dimensiune redusă a datelor într-un spațiu cu dimensiuni mari și apoi să transformăm distribuția într-o reprezentare compactă și structurată?} Pentru orice sistem inteligent, natural sau creat de om, o astfel de reprezentare poate fi considerată în general ca o {\em memorie} sau {\em cunoaștere} învățată din datele percepute din lumea exterioară.

Acest manual își propune să ofere o introducere sistematică în principiile matematice și computaționale pentru învățarea reprezentărilor (profunde) ale acestor distribuții de date pentru {\em studenții din ultimii ani de licență și studenții începători de masterat}. Principalele cerințe preliminare pentru această carte sunt algebra liniară de nivel licență, probabilități/statistică și optimizare. O oarecare familiaritate cu conceptele de bază din procesarea semnalelor (în special reprezentarea rară și detectarea comprimată), teoria informației și controlul cu feedback ar îmbunătăți aprecierea dumneavoastră.

Principala motivație pentru scrierea acestei cărți este că au existat dezvoltări extraordinare în ultimii câțiva ani, de către autori și mulți colegi, care urmăresc să stabilească o abordare principială și riguroasă pentru înțelegerea rețelelor neuronale profunde și, mai general, a inteligenței în sine. Metodologia deductivă promovată de această nouă abordare este în contrast direct și foarte complementară cu metodologia dominantă din spatele practicilor actuale de inteligență artificială, care este în mare parte inductivă și bazată pe încercare și eroare. Lipsa de înțelegere a unor astfel de modele și sisteme AI puternice a condus la creșterea entuziasmului excesiv și a temerilor în societate. Credem că o încercare serioasă de a stabili o abordare principială pentru înțelegerea inteligenței este mai necesară ca niciodată. Un obiectiv general al acestei cărți este să ofere dovezi teoretice și experimentale solide care arată că acum este posibil să studiem inteligența ca un subiect științific și matematic. Prin urmare, se poate vedea această carte ca o primă încercare de a dezvolta {\em o Teorie Matematică a Inteligenței}.

La nivel tehnic, cadrul teoretic prezentat în această carte ajută la reconcilierea unei lacune de lungă durată între abordarea clasică de modelare a structurilor de date care se bazează în principal pe modele geometrice, algebrice și probabilistice analitice (de exemplu, subspații, gaussiene și ecuații) și abordarea „modernă" care se bazează pe modele non-parametrice proiectate empiric (de exemplu, rețele profunde). După cum se dovedește, o unificare a celor două metodologii aparent separate devine posibilă și chiar naturală dacă cineva realizează că toate încearcă să modeleze și să învețe structuri {\em cu dimensiuni reduse} în distribuția de date de interes. Acestea sunt doar modalități diferite de a urmări, reprezenta și exploata structurile cu dimensiuni reduse. Din această perspectivă, chiar și multe tehnici computaționale aparent fără legătură, dezvoltate independent în domenii separate în momente diferite, pot fi acum mai bine înțelese într-un cadru computațional comun și probabil pot fi studiate împreună de acum înainte. După cum vom vedea în această carte, aceste tehnici includ, dar nu se limitează la, codarea-decodarea compresivă cu pierderi dezvoltată în teoria informației și teoria codării, difuzia și îndepărtarea zgomotului în procesarea semnalelor și învățarea automată, și tehnicile de continuare precum metodele Lagrangiene augmentate pentru optimizarea constrânsă.

Credem că cadrul conceptual și computațional unificat prezentat în această carte va fi de mare valoare pentru cititorii care doresc cu adevărat să clarifice misterele și neînțelegerile despre rețelele neuronale profunde și inteligența (artificială). În plus, cadrul este menit să ofere cititorilor principii directoare pentru dezvoltarea unor sisteme semnificativ mai bune și cu adevărat inteligente în viitor. Mai specific, pe lângă o introducere informală (capitol), conținutul tehnic principal al cărții va fi organizat în șase subiecte strâns legate (capitole):
\begin{enumerate}
\item Vom începe cu modelele clasice și cele mai de bază de Analiză a Componentelor Principale (PCA), Analiză a Componentelor Independente (ICA) și Învățarea Dicționarului (DL), care presupun că distribuțiile cu dimensiuni reduse de interes au structuri liniare și independente. Din aceste modele idealiste simple care sunt bine studiate și înțelese în procesarea semnalelor și detectarea comprimată, vom introduce ideile cele mai de bază și importante pentru cum să învățăm distribuții cu dimensiuni reduse.

\item Pentru a generaliza aceste modele clasice și soluțiile lor la distribuții generale cu dimensiuni reduse, introducem un principiu computațional universal pentru învățarea acestor distribuții: {\em compresia}. După cum vom vedea, compresia datelor oferă o viziune unificatoare a tuturor abordărilor clasice și moderne aparent diferite pentru învățarea distribuției sau reprezentării, inclusiv reducerea dimensionalității, minimizarea entropiei, potrivirea scorului pentru îndepărtarea zgomotului și compresia cu pierderi cu distorsiune de rată.

\item În cadrul acestui cadru unificator, Rețelele Neuronale Profunde moderne (DNN), cum ar fi ResNet, CNN și Transformer, pot fi toate interpretate matematic ca algoritmi de optimizare (desfășurați) care obțin iterativ o compresie mai bună și reprezentări mai bune prin reducerea lungimii/ratei de codare sau obținerea de informații. Nu numai că acest cadru ajută la explicarea arhitecturilor de rețea profundă proiectate empiric până acum, dar conduce și la noi designuri de arhitectură care pot fi semnificativ mai simple și mai eficiente.

\item În plus, pentru a asigura că reprezentarea învățată pentru o distribuție de date este corectă și consistentă, arhitecturile de {\em auto-codare} care constau atât din codare, cât și din decodare devin necesare. Pentru ca un sistem de învățare să fie complet automat și continuu, vom introduce un cadru puternic de {\em transcriere în buclă închisă} care permite unui sistem de auto-codare să se auto-corecteze și astfel să se auto-îmbunătățească printr-un joc minimax între codificator și decodificator.

\item Vom studia, de asemenea, cum distribuția și reprezentarea datelor învățate pot fi utilizate ca o prioritate sau constrângere puternică pentru a efectua inferența Bayesiană care facilitează aproape toate tipurile de sarcini și setări care sunt populare în practica inteligenței artificiale moderne, inclusiv estimarea condiționată, completarea și generarea de date din lumea reală cu dimensiuni mari, cum ar fi imagini și texte.

\item Nu în ultimul rând, pentru a conecta teoria cu practica, vom demonstra pas cu pas cum să învățăm eficient și eficace reprezentări profunde ale distribuțiilor de date cu dimensiuni reduse cu seturi de date la scară largă, inclusiv atât imagini, cât și texte, și să le folosim în multe aplicații practice, cum ar fi clasificarea imaginilor, completarea imaginilor, segmentarea imaginilor, generarea imaginilor și sarcini similare pentru date text.
\end{enumerate}

Pentru a rezuma, conținutul tehnic prezentat în această carte stabilește conexiuni conceptuale și tehnice puternice între abordarea analitică clasică și abordarea computațională modernă, între modele parametrice simple și modele non-parametrice profunde, între diverse practici inductive și un cadru deductiv unificat din principii prime. Vom dezvălui că multe abordări aparent fără legătură sau chiar concurente, deși dezvoltate în domenii separate în momente diferite, toate se străduiesc să atingă un obiectiv comun:
\begin{quote}
\centering{\em urmărirea și exploatarea distribuțiilor intrinseci cu dimensiuni reduse ale datelor cu dimensiuni mari.}
\end{quote}
În acest scop, cartea ne va purta printr-o călătorie completă de la formularea teoretică la verificarea matematică la realizarea computațională la aplicații practice.




\end{document}